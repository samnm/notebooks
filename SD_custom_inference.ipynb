{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNoW1g4IWG746gs7jqG/ulZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samnm/notebooks/blob/main/SD_custom_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Dependencies\n",
        "%cd /content/\n",
        "!git clone https://github.com/TheLastBen/diffusers | true\n",
        "!pip install -q typing-extensions==4.1\n",
        "!pip install -q bitsandbytes\n",
        "!pip install -q transformers\n",
        "!pip install -q termcolor\n",
        "!pip install --ignore-installed -q git+https://github.com/TheLastBen/diffusers\n",
        "!pip install -q accelerate==0.12.0\n",
        "!pip install -q OmegaConf\n",
        "!pip install -q wget\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -U -q --no-cache-dir gdown\n",
        "!wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
        "!mv Deps Deps.7z\n",
        "!7z x Deps.7z\n",
        "!cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "!rm Deps.7z\n",
        "!rm -rf /content/usr\n",
        "!sed -i 's@else prefix + \": \"@else prefix + \"\"@g' /usr/local/lib/python3.7/dist-packages/tqdm/std.py"
      ],
      "metadata": {
        "id": "qEnEZ5M3TRZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # xformers\n",
        "\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "import wget\n",
        "import time\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "elif 'A100' in s:\n",
        "  gpu = 'A100'\n",
        "\n",
        "while True:\n",
        "    try: \n",
        "        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "    raise Exception('\u001b[1;31mit seems that your GPU is not supported at the moment')\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "  \n",
        "elif (gpu=='P100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='V100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='A100'):\n",
        "  %cd /usr/local/lib/python3.7/diffusers/models/\n",
        "  !rm /usr/local/lib/python3.7/diffusers/models/attention.py\n",
        "  wget.download('https://raw.githubusercontent.com/huggingface/diffusers/269109dbfbbdbe2800535239b881e96e1828a0ef/src/diffusers/models/attention.py') \n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDONE !')"
      ],
      "metadata": {
        "id": "yOrHB_aWTSXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-avTO7n3QX0D"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "weights_url = \"\" #@param {type:\"string\"}\n",
        "ckpt_path = '/content/weights.ckpt'\n",
        "if weights_url.startswith('gs://'):\n",
        "    subprocess.check_output(['gcloud', 'storage', 'cp', weights_url, ckpt_path])\n",
        "else:\n",
        "    subprocess.check_output(['wget', weights_url, '-O', ckpt_path])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "!python /content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$ckpt_path\" --dump_path /content/stable-diffusion-v1-5\n",
        "!rm /content/convert_original_stable_diffusion_to_diffusers.py"
      ],
      "metadata": {
        "id": "apf3UWQcS5Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"/content/stable-diffusion-v1-5\")\n",
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "kyjAHZ3-TmM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\" #@param {type:\"string\"}\n",
        "image = pipe(prompt).images[0]\n",
        "image.save(\"out.png\")"
      ],
      "metadata": {
        "id": "giPTiBVBpYXF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}